{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_endpoint_connect(bearer_token, query, st, et, next_token):\n",
    "    \n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    query_params = {\n",
    "                    'query': query,\n",
    "                    'start_time': st,\n",
    "                    'end_time': et,\n",
    "                    'max_results': 500,\n",
    "                    'tweet.fields': 'id,text,author_id,created_at,geo,lang,public_metrics,in_reply_to_user_id',               \n",
    "                   }\n",
    "    \n",
    "    if (next_token is not None):\n",
    "        url = \"https://api.twitter.com/2/tweets/search/all?next_token={}\".format(next_token)\n",
    "    else:\n",
    "        url = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "    \n",
    "    response = requests.request(\"GET\", url, params=query_params, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(bearer_token, n, fn, sq, st, et):\n",
    "    \n",
    "    rl_count = 0\n",
    "    count = 0\n",
    "    flag = True\n",
    "    first = True\n",
    "\n",
    "\n",
    "    while flag:\n",
    "        \n",
    "        if rl_count==300:\n",
    "            time.sleep(600)\n",
    "            print('Rate limit cooldown 10 mins.')\n",
    "\n",
    "        if count >= n and n!=0:\n",
    "            break\n",
    "        if not first:\n",
    "            json_response = search_endpoint_connect(bearer_token, sq, st, et, next_token)\n",
    "        else:\n",
    "            json_response = search_endpoint_connect(bearer_token, sq, st, et, next_token=None)\n",
    "        \n",
    "        result_count = json_response['meta']['result_count']\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            next_token = json_response['meta']['next_token']\n",
    "        \n",
    "            if result_count is not None and result_count > 0 and next_token is not None:\n",
    "            \n",
    "                df = pd.json_normalize(json_response['data'])\n",
    "                df = df.reindex(columns=['id', 'author_id', 'created_at', 'text', 'lang', 'public_metrics.retweet_count',\n",
    "                                     'public_metrics.reply_count', 'public_metrics.like_count', 'public_metrics.quote_count',\n",
    "                                    'in_reply_to_user_id', 'geo.place_id', 'geo.coordinates.type', 'geo.coordinates.coordinates'])\n",
    "                if not first:\n",
    "                    df.to_csv('%s.csv'%fn, mode='a', encoding='utf-8', index=False, header=None)\n",
    "                else:\n",
    "                    df.to_csv('%s.csv'%fn, encoding='utf-8', index=False)\n",
    "\n",
    "                time.sleep(1)\n",
    "                count += result_count\n",
    "                print('Tweets downloaded: '+str(count))\n",
    "        else:\n",
    "            flag = False\n",
    "        rl_count += 1\n",
    "        first = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter your bearer token\n",
    "bearer_token = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "\n",
    "#Set number of tweets to be downloaded. Enter 0 for no limits\n",
    "no_of_tweets = 20\n",
    "\n",
    "#Specify the name of the output csv file. Do not include .csv\n",
    "file_name = 'downloaded_tweets'\n",
    "\n",
    "#Enter your search query. Refer to https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query\n",
    "search_query = '(nostalgia OR #nostalgia) lang:en -is:retweet -is:reply place_country:US'\n",
    "\n",
    "#Set the beginning date and time in YYYY-MM-DDTHH:MM:SSZ format\n",
    "start_time = \"2019-11-27T00:00:00Z\"\n",
    "\n",
    "#Set the ending date and time in YYYY-MM-DDTHH:MM:SSZ format\n",
    "end_time = \"2019-11-28T23:59:59Z\"\n",
    "\n",
    "main(bearer_token, no_of_tweets, file_name, search_query, start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
